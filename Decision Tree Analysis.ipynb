{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOUBTS:\n",
    "- Cell with value: 999999999\n",
    "- Have to normalize? Think not\n",
    "- About parameters\n",
    "    - splitter\n",
    "    - max_features\n",
    "    - max_leaf_nodes\n",
    "    - min_impurity_decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import graphviz\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UTILS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATABASE_DIR = '/home/macdowell/Workspace/Decision-Tree-Analysis/database/'\n",
    "OUTPUT_DIR = 'output/'\n",
    "\n",
    "def get_entries_name_inside_dir(path):\n",
    "    smell_folders = os.listdir(path)\n",
    "    return smell_folders\n",
    "\n",
    "def dataframe_appended_from_smell_folder(folder_path):\n",
    "    csv_files = os.listdir(folder_path)\n",
    "    df = None\n",
    "    \n",
    "    for csv in csv_files:\n",
    "        if 'lock' in csv:\n",
    "            continue\n",
    "        \n",
    "        if df is None:\n",
    "            df = pd.read_csv(folder_path + '/' + csv)\n",
    "        else:\n",
    "            df_aux = pd.read_csv(folder_path + '/' + csv)\n",
    "            df = pd.concat([df, df_aux])\n",
    "    return df\n",
    "\n",
    "def dict_to_csv(output_path, dict_to_save, column_name):\n",
    "    df = pd.DataFrame.from_dict(dict_to_save, orient='columns')\n",
    "    df.index.names = [column_name]\n",
    "    df.to_csv(output_path + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effectivity on differents database's percents:\n",
    "\n",
    "- RQ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macdowell/Programs/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0\n",
      "train_percent          \n",
      "0.25           0.512834\n",
      "0.50           0.538689\n",
      "0.75           0.566336\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(X, y, df, train_percent, effectivity_dict, smell, cv_splits):\n",
    "    \n",
    "    ss = ShuffleSplit(n_splits=cv_splits, train_size=train_percent, test_size=0.25)\n",
    "    score_list = []\n",
    "    \n",
    "    for train_index, test_index in ss.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        \n",
    "        score = perform_models(\n",
    "            [\n",
    "                DecisionTreeClassifier()\n",
    "            ],\n",
    "            X_train, X_test,\n",
    "            y_train, y_test,\n",
    "            df,\n",
    "            train_percent,\n",
    "            effectivity_dict,\n",
    "            smell\n",
    "        )\n",
    "        \n",
    "        score_list.append(score)\n",
    "        \n",
    "        # Adding scores into dict:\n",
    "    effectivity_dict[smell][train_percent] = sum(score_list)/len(score_list)\n",
    "        \n",
    "\n",
    "def perform_models(classifiers, X_train, X_test, y_train, y_test, df, train_percent, effectivity_dict, smell):\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        # Creating key index in dict to save evaluation metrics value:\n",
    "        #string += classifier.__class__.__name__\n",
    "\n",
    "        # Train:\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        #TODO: Make Viz woks\n",
    "        # Viz:\n",
    "        '''\n",
    "        dot_data = tree.export_graphviz(classifier, out_file=None, \n",
    "                      feature_names=df.columns,  \n",
    "                      class_names=['smell', 'not smell'],\n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "        graph = graphviz.Source(dot_data)  \n",
    "        graph\n",
    "        '''\n",
    "        \n",
    "        # Predicting values with model:\n",
    "        predicteds = classifier.predict(X_test)\n",
    "        \n",
    "        # Getting score metrics:\n",
    "        return f1_score(y_test, predicteds)\n",
    "        \n",
    "\n",
    "smell_folders = get_entries_name_inside_dir(DATABASE_DIR)\n",
    "train_percents = [0.25, 0.5, 0.75]\n",
    "\n",
    "effectivity_dict = {}\n",
    "\n",
    "for smell in smell_folders:\n",
    "    smell_metrics_df = dataframe_appended_from_smell_folder(DATABASE_DIR + smell)\n",
    "\n",
    "    effectivity_dict[smell] = {}\n",
    "    \n",
    "    for percent in train_percents:\n",
    "        \n",
    "        effectivity_dict[smell][percent] = -1\n",
    "        \n",
    "        if '0' in smell_metrics_df.columns:\n",
    "            smell_metrics_df = smell_metrics_df.drop(columns=['0'], axis=1)\n",
    "\n",
    "        for c in smell_metrics_df.columns:\n",
    "            smell_metrics_df[c] = np.nan_to_num(smell_metrics_df[c])\n",
    "\n",
    "        X = smell_metrics_df.iloc[:, smell_metrics_df.columns != 'Smell']\n",
    "        y = smell_metrics_df.iloc[:, smell_metrics_df.columns == 'Smell']\n",
    "        \n",
    "        evaluate_model(X, y, smell_metrics_df, percent, effectivity_dict, smell, cv_splits=5)\n",
    "\n",
    "#print(effectivity_dict)\n",
    "# Writing results in CSV\n",
    "dict_to_csv(OUTPUT_DIR + 'RQ1', effectivity_dict, 'train_percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOT ABOUT RQ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 648x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "#Size of the plot\n",
    "plt.rcParams[\"figure.figsize\"] = [9,6]\n",
    "df = pd.read_csv('output/RQ1.csv')\n",
    "\n",
    "for smell in smell_folders:\n",
    "    ax = sns.lineplot(x=\"train_percent\", y=smell, data=df)\n",
    "    ax.set(xlabel='Database train percent', ylabel='f1 score')\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(\"output/images/RQ1/\"+ smell + \".png\")\n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The maximum depth of the tree:\n",
    "\n",
    "- RQ2)\n",
    "\n",
    "Tune parameter `max_depth` = (3, 5, 7, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macdowell/Programs/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(X, y, df, max_depth, effectivity_dict, smell, cv_splits):\n",
    "    \n",
    "    ss = ShuffleSplit(n_splits=cv_splits, train_size=0.70, test_size=0.30)\n",
    "    score_list = []\n",
    "    \n",
    "    for train_index, test_index in ss.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        \n",
    "        score = perform_models(\n",
    "            [\n",
    "                DecisionTreeClassifier(max_depth=max_depth)\n",
    "            ],\n",
    "            X_train, X_test,\n",
    "            y_train, y_test,\n",
    "            df,\n",
    "            effectivity_dict,\n",
    "            smell\n",
    "        )\n",
    "        \n",
    "        score_list.append(score)\n",
    "        \n",
    "        # Adding scores into dict:\n",
    "    effectivity_dict[smell][max_depth] = sum(score_list)/len(score_list)\n",
    "        \n",
    "\n",
    "def perform_models(classifiers, X_train, X_test, y_train, y_test, df, effectivity_dict, smell):\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        # Creating key index in dict to save evaluation metrics value:\n",
    "        #string += classifier.__class__.__name__\n",
    "\n",
    "        # Train:\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        #TODO: Make Viz woks\n",
    "        # Viz:\n",
    "        '''\n",
    "        dot_data = tree.export_graphviz(classifier, out_file=None, \n",
    "                      feature_names=df.columns,  \n",
    "                      class_names=['smell', 'not smell'],\n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "        graph = graphviz.Source(dot_data)  \n",
    "        graph\n",
    "        '''\n",
    "        \n",
    "        # Predicting values with model:\n",
    "        predicteds = classifier.predict(X_test)\n",
    "        \n",
    "        # Getting score metrics:\n",
    "        return f1_score(y_test, predicteds)\n",
    "\n",
    "\n",
    "smell_folders = get_entries_name_inside_dir(DATABASE_DIR)\n",
    "tree_max_depth = [3, 5, 7, 10]\n",
    "\n",
    "effectivity_dict = {}\n",
    "\n",
    "for smell in smell_folders:\n",
    "    smell_metrics_df = dataframe_appended_from_smell_folder(DATABASE_DIR + smell)\n",
    "\n",
    "    effectivity_dict[smell] = {}\n",
    "    \n",
    "    for max_depth in tree_max_depth:\n",
    "        \n",
    "        effectivity_dict[smell][max_depth] = -1.0\n",
    "        \n",
    "        if '0' in smell_metrics_df.columns:\n",
    "            smell_metrics_df = smell_metrics_df.drop(columns=['0'], axis=1)\n",
    "\n",
    "        for c in smell_metrics_df.columns:\n",
    "            smell_metrics_dbf[c] = np.nan_to_num(smell_metrics_df[c])\n",
    "\n",
    "        X = smell_metrics_df.iloc[:, smell_metrics_df.columns != 'Smell']\n",
    "        y = smell_metrics_df.iloc[:, smell_metrics_df.columns == 'Smell']\n",
    "        \n",
    "        evaluate_model(X, y, smell_metrics_df, max_depth, effectivity_dict, smell, cv_splits=5)\n",
    "    \n",
    "dict_to_csv(OUTPUT_DIR + 'RQ2', effectivity_dict, 'max_depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot about RQ2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 648x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "#Size of the plot\n",
    "plt.rcParams[\"figure.figsize\"] = [9,6]\n",
    "df = pd.read_csv('output/RQ2.csv')\n",
    "\n",
    "for smell in smell_folders:\n",
    "    ax = sns.lineplot(x=\"max_depth\", y=smell, data=df)\n",
    "    ax.set(xlabel='Max depth of tree', ylabel='f1 score')\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(\"output/images/RQ2/\"+ smell + \".png\")\n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effectivity on different database's percents with different maximum depth of the tree:\n",
    "- RQ3)\n",
    "\n",
    "Train with 25%, 50%, 75% and max depth of 3, 5, 7, 10.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macdowell/Programs/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/macdowell/Programs/miniconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     3         5         7         10\n",
      "train_percent                                        \n",
      "0.25           0.327910  0.448932  0.451033  0.524920\n",
      "0.50           0.554922  0.511886  0.580952  0.607942\n",
      "0.75           0.579409  0.522439  0.589584  0.532583\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(X, y, df, train_percent, max_depth, effectivity_dict, smell, cv_splits):\n",
    "    \n",
    "    ss = ShuffleSplit(n_splits=cv_splits, train_size=train_percent, test_size=0.25)\n",
    "    score_list = []\n",
    "    \n",
    "    for train_index, test_index in ss.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        \n",
    "        score = perform_models(\n",
    "            [\n",
    "                DecisionTreeClassifier(max_depth=max_depth)\n",
    "            ],\n",
    "            X_train, X_test,\n",
    "            y_train, y_test,\n",
    "            df,\n",
    "            effectivity_dict\n",
    "        )\n",
    "        \n",
    "        score_list.append(score)\n",
    "        \n",
    "        # Adding scores into dict:\n",
    "    effectivity_dict[smell][train_percent][max_depth] = sum(score_list)/len(score_list)\n",
    "        \n",
    "\n",
    "def perform_models(classifiers, X_train, X_test, y_train, y_test, df, effectivity_dict):\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        # Creating key index in dict to save evaluation metrics value:\n",
    "        #string += classifier.__class__.__name__\n",
    "\n",
    "        # Train:\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        #TODO: Make Viz woks\n",
    "        # Viz:\n",
    "        '''\n",
    "        dot_data = tree.export_graphviz(classifier, out_file=None, \n",
    "                      feature_names=df.columns,  \n",
    "                      class_names=['smell', 'not smell'],\n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "        graph = graphviz.Source(dot_data)  \n",
    "        graph\n",
    "        '''\n",
    "        \n",
    "        # Predicting values with model:\n",
    "        predicteds = classifier.predict(X_test)\n",
    "        \n",
    "        # Getting score metrics:\n",
    "        return f1_score(y_test, predicteds)\n",
    "        \n",
    "\n",
    "smell_folders = get_entries_name_inside_dir(DATABASE_DIR)\n",
    "\n",
    "train_percents = [0.25, 0.5, 0.75]\n",
    "tree_max_depth = [3, 5, 7, 10]\n",
    "\n",
    "effectivity_dict = {}\n",
    "\n",
    "for smell in smell_folders:\n",
    "    smell_metrics_df = dataframe_appended_from_smell_folder(DATABASE_DIR + smell)\n",
    "\n",
    "    effectivity_dict[smell] = {}\n",
    "    \n",
    "    for percent in train_percents:\n",
    "        \n",
    "        effectivity_dict[smell][percent] = {}\n",
    "        \n",
    "        for max_depth in tree_max_depth:\n",
    "\n",
    "            effectivity_dict[smell][percent][max_depth] = -1\n",
    "            \n",
    "            if '0' in smell_metrics_df.columns:\n",
    "                smell_metrics_df = smell_metrics_df.drop(columns=['0'], axis=1)\n",
    "\n",
    "            for c in smell_metrics_df.columns:\n",
    "                smell_metrics_df[c] = np.nan_to_num(smell_metrics_df[c])\n",
    "\n",
    "            X = smell_metrics_df.iloc[:, smell_metrics_df.columns != 'Smell']\n",
    "            y = smell_metrics_df.iloc[:, smell_metrics_df.columns == 'Smell']\n",
    "\n",
    "            evaluate_model(X, y, smell_metrics_df, percent, max_depth, effectivity_dict, smell, cv_splits=5)\n",
    "            \n",
    "dict_to_csv(OUTPUT_DIR + 'RQ3', effectivity_dict, 'train_percent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
